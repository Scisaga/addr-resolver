# address_resolver.py
import requests
import json
import logging,time,os,sys
import re
from typing import Dict, List, Any
from util.address_db import search_address
from util.similarity import score_main_tokens, core_keyword_overlap_ratio
from config import logger
from func.amap_call import amap_inputtips, amap_geocode, amap_around_search, amap_poi_search, regeo
from func.qwen_call import call_qwen
from func.struct_llm_call import infer


def get_best_poi(pois: List[Dict], keyword: str, threshold: float = 70.0) -> Dict | None:
    """
    ä» POI åˆ—è¡¨ä¸­æ‰¾åˆ°ä¸ keyword ç›¸ä¼¼åº¦æœ€é«˜çš„ POIï¼Œè‹¥ç›¸ä¼¼åº¦ â‰¥ thresholdï¼Œåˆ™è¿”å›è¯¥ POIï¼Œå¦åˆ™è¿”å› Noneã€‚
    :param pois: POI åˆ—è¡¨
    :param keyword: æŸ¥è¯¢å…³é”®è¯
    :param threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
    :return: æœ€ä½³åŒ¹é…çš„ POI æˆ– None
    """
    best_poi = None
    best_score = 0.0

    for poi in pois:
        name = poi.get("name", "")
        address = poi.get("address", "")
        location = poi.get("location", "")
        if not location:
            continue

        name_score = score_main_tokens(keyword, name)
        address_score = score_main_tokens(keyword, address)
        score = max(name_score, address_score)

        if score > best_score:
            best_score = score
            best_poi = poi

    if best_poi and best_score >= threshold:
        logger.info(f"ğŸ¯ åŒ¹é…æˆåŠŸï¼š{best_poi['name']} | {best_poi['address']} | ç›¸ä¼¼åº¦: {best_score}")
        return best_poi
    else:
        logger.info(f"âŒ æ— åŒ¹é…ç»“æœæˆ–ç›¸ä¼¼åº¦ä½äºé˜ˆå€¼ {threshold}ï¼Œæœ€é«˜ä¸º {best_score:.2f}")
        return None


def judge_best_by_auxiliary(anchor_location: str, candidates: List[Dict], auxiliary: str) -> List[Dict]:
    """
    ä½¿ç”¨å¤§æ¨¡å‹åˆ¤æ–­æ¯ä¸ªå€™é€‰ POI ä¸è¾…åŠ©æè¿°çš„åŒ¹é…ç¨‹åº¦ï¼Œä¸ºæ¯ä¸ªå€™é€‰æ·»åŠ  auxiliary_score å­—æ®µï¼ˆ0~100ï¼‰ã€‚
    :param anchor_location: é”šç‚¹åæ ‡ (lng, lat)
    :param candidates: å€™é€‰ POI åˆ—è¡¨ï¼Œè¦æ±‚æ¯ä¸ªå«æœ‰ location å­—æ®µ
    :param auxiliary: ç”¨æˆ·è¾“å…¥ä¸­çš„è¾…åŠ©å­—æ®µï¼Œå¦‚â€œè¥¿åŒ—è§’â€â€œå¾€ä¸œèµ°100ç±³â€â€œå¯¹é¢â€ç­‰
    :return: æ›´æ–°åçš„ candidatesï¼Œæ¯ä¸ªåŒ…å« auxiliary_score å­—æ®µ
    """
    poi_list = [{c["name"]: c["location"]} for c in candidates]
    prompt = f"""å·²çŸ¥å‚è€ƒç‚¹åæ ‡ä¸º {anchor_location}ï¼Œç”¨æˆ·æè¿°ä¸ºâ€œ{auxiliary}â€ï¼Œ
ä¸‹åˆ—æ˜¯å€™é€‰ POI çš„åç§°å’Œç»çº¬åº¦ï¼Œè¯·ä½ åˆ¤æ–­å“ªä¸ªæœ€å¯èƒ½æ˜¯ç”¨æˆ·æ‰€æŒ‡çš„ç›®æ ‡ï¼Œå¹¶ä¸ºæ¯ä¸ªå€™é€‰é¡¹æ‰“ä¸€ä¸ªåŒ¹é…åˆ†æ•°ï¼ˆ0-100ï¼‰ã€‚
è¾“å‡ºæ ¼å¼å¦‚ä¸‹ï¼ˆJSONï¼‰ï¼š
{{
  "åç§°1": 85,
  "åç§°2": 20,
  ...
}}
å€™é€‰åˆ—è¡¨ï¼š
{json.dumps(poi_list, ensure_ascii=False, indent=2)}
è¯·ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¿”å›ï¼š
"""

    response = call_qwen(prompt)

    try:
        score_map = json.loads(response)
        logger.info(f"ğŸ¯ å¤§æ¨¡å‹è¾…åŠ©æ‰“åˆ†ç»“æœï¼š{score_map}")
    except Exception as e:
        logger.warning(f"âš ï¸ å¤§æ¨¡å‹è¿”å›éæ ‡å‡† JSONï¼Œfallback æ‰€æœ‰åˆ†æ•°ä¸º 0ã€‚åŸå§‹è¿”å›ï¼š{response}")
        score_map = {}

    for poi in candidates:
        name = poi.get("name", "")
        poi["auxiliary_score"] = round(score_map.get(name, 0.0), 2)

    return candidates


def search_nearby_by_fields(city: str, fields: Dict) -> List[Dict]:
    """
    æ ¹æ®ç»“æ„åŒ–å­—æ®µæ‰§è¡Œå‘¨è¾¹æœç´¢ï¼ˆFallbackï¼‰
    ä¼˜å…ˆä½¿ç”¨ AP å­—æ®µä½œä¸ºå®šä½é”šç‚¹ï¼Œç»“åˆ U/AP/I å­—æ®µæå–å…³é”®è¯æœç´¢å‘¨è¾¹ï¼Œ
    å¹¶ç»“åˆ I å­—æ®µè¾…åŠ©ä½ç½®ä¿¡æ¯è°ƒç”¨å¤§æ¨¡å‹åˆ¤æ–­å„ä¸ª POI çš„åŒ¹é…ç¨‹åº¦ã€‚
    :param city: åŸå¸‚å
    :param fields: åŒ…å«ç»“æ„å­—æ®µçš„å­—å…¸ï¼ˆAP, U, Iç­‰ï¼‰
    :return: POI åˆ—è¡¨ï¼Œæ¯ä¸ª POI åŒ…å« auxiliary_score å­—æ®µï¼ˆ0~100ï¼‰
    """
    anchor = fields.get("D")
    logger.info(f"{city} æœç´¢é”šç‚¹ï¼ˆDï¼‰: {anchor}")

    loc = amap_geocode(city, anchor) # type: ignore
    print(f"é”šç‚¹ä½ç½®ï¼š{loc}")
    if not loc:
        logger.error("âŒ APé”šç‚¹å®šä½å¤±è´¥")
        return []

    unit = fields.get("U", "")
    ap = fields.get("AP", "")
    auxiliary = fields.get("I", "")

    keywords = []

    # Step 0: ä» AP ä¸­æå–å…³é”®è¯ï¼ˆå¦‚ æ•™å­¦æ¥¼ï¼‰
    if not keywords and ap:
        for token in ["æ•™å­¦æ¥¼", "å†™å­—æ¥¼", "å¹¿åœº", "å¤§å¦", "ä¸­å¿ƒ", "é—¨è¯Š", "å…¬å¯“", "å…»æ®–å¡˜", "æœºç”µå‚"]:
            if token in ap:
                keywords.append(token)
                break

    # Step 1: ä» U æå–å…³é”®è¯ï¼ˆå¦‚ 6å·æ¥¼ï¼‰
    if unit:
        for token in ["å·æ¥¼", "æ ‹", "å•å…ƒ", "å®¿èˆ", "æ¥¼", "é—¨", "æ¥¼å±‚", "éƒ¨"]:
            if token in unit:
                keywords.append(unit)
                break

    # Step 3: è¾…åŠ©å­—æ®µè§¦å‘æ¨¡ç³Šè¯
    if auxiliary:
        keywords.append("æ¥¼")

    # Step 4: fallback é»˜è®¤å…³é”®è¯
    if not keywords:
        keywords.append("æ¥¼")

    logger.info(f"ğŸ” å‘¨è¾¹æœç´¢å…³é”®è¯å€™é€‰: {keywords}")

    # å¤šå…³é”®è¯å°è¯•
    pois = []
    for kw in set(keywords):
        pois += amap_around_search(loc, kw)

    if not pois:
        return []

    # Step 5: è¾…åŠ©å­—æ®µè¾…åŠ©åˆ¤æ–­ï¼ˆè°ƒç”¨å¤§æ¨¡å‹æ‰“åˆ†ï¼‰
    if auxiliary:
        logger.info(f"ğŸ§­ ä½¿ç”¨è¾…åŠ©å­—æ®µâ€œ{auxiliary}â€è°ƒç”¨å¤§æ¨¡å‹è¾…åŠ©æ‰“åˆ†")
        pois = judge_best_by_auxiliary(anchor_location=loc, candidates=pois, auxiliary=auxiliary)

        # æ’åºï¼šæŒ‰è¾…åŠ©è¯„åˆ†é™åºæ’åˆ—
        pois.sort(key=lambda p: p.get("auxiliary_score", 0), reverse=True)

    return pois


def similarity_score(addr: str, candidate: str) -> float:
    """
    ç»¼åˆè®¡ç®—åœ°å€å­—ç¬¦ä¸²ä¹‹é—´çš„ç›¸ä¼¼åº¦
    :param addr: è¾“å…¥åœ°å€
    :param candidate: å€™é€‰åœ°å€
    :return: 0~100 çš„ç›¸ä¼¼åº¦åˆ†æ•°
    """
    t = 100 * score_main_tokens(addr, candidate)

    k = core_keyword_overlap_ratio(addr, candidate)

    final_score = 1 * t + 0.0 * k

    logger.info(f"ç›¸ä¼¼åº¦æ¯”è¾ƒï¼š{addr} --> {candidate}, token: {t:.2f}, keyword: {k:.2f}, " +
          f"ç›¸ä¼¼åº¦å¾—åˆ†: {final_score:.2f}")

    return final_score


def normalize_poi_id(poi: Dict) -> str | None:
    """
    æå–å¹¶è§„æ•´ POI çš„ id å­—æ®µä¸ºå­—ç¬¦ä¸²å½¢å¼ï¼Œæ”¯æŒ str/int/list ç±»å‹ã€‚
    - å¦‚æœä¸º listï¼Œåˆ™è¿”å›ç¬¬ä¸€ä¸ªå…ƒç´ çš„å­—ç¬¦ä¸²ï¼›
    - å¦‚æœä¸ºç©ºæˆ–æ ¼å¼éæ³•ï¼Œåˆ™è¿”å› Noneã€‚
    """
    poi_id = poi.get("id")

    if isinstance(poi_id, list):
        if poi_id:
            return str(poi_id[0])
        else:
            logger.warning(f"âš ï¸ POI id æ˜¯ç©ºåˆ—è¡¨ï¼Œè·³è¿‡ï¼š{poi}")
            return None
    elif isinstance(poi_id, (str, int)):
        return str(poi_id)
    else:
        logger.warning(f"âš ï¸ POI id ç±»å‹éæ³•ï¼ˆ{type(poi_id)}ï¼‰ï¼Œè·³è¿‡ï¼š{poi}")
        return None

def merge_pois(*poi_lists) -> List:
    """
    åˆå¹¶å¤šä¸ªæœç´¢ç»“æœï¼Œå»é‡ï¼ˆå¯æ ¹æ® poi åç§°æˆ– idï¼‰
    :param poi_lists: ä»»æ„æ•°é‡çš„ POI åˆ—è¡¨
    :return: åˆå¹¶å»é‡åçš„ POI åˆ—è¡¨
    """
    all_pois = {}
    for pois in poi_lists:          # éå†æ¯ä¸ªæ•°ç»„
        for poi in pois:            # éå†æ•°ç»„é‡Œçš„æ¯ä¸ªå…ƒç´ 
            poi_id = normalize_poi_id(poi)
            if poi_id and poi_id not in all_pois:
                all_pois[poi_id] = poi

    return list(all_pois.values())


# æ­£åˆ™æ¨¡å¼ï¼šåŒ¹é…åœ°çº§å¸‚æˆ–çœç›´ç®¡å¿ï¼ˆéè´ªå©ªï¼‰
pattern = re.compile(r'([\u4e00-\u9fa5]{2,20}?(å¸‚|åœ°åŒº|è‡ªæ²»å·|ç›Ÿ|å¿|è‡ªæ²»å¿|æ——|è‡ªæ²»æ——|æ—åŒº|ç‰¹åŒº|åŒº))')

def extract_first_region(text: str) -> str:
    match = pattern.search(text)
    if match:
        return match.group(1)
    return ""

def build_structured_fields(raw_address: str, structured: Any) -> Dict[str, str]:
    fields = {"C": "", "D": "", "AP": "", "U": "", "I": "", "T": ""}

    if not isinstance(structured, dict):
        return fields

    tags = structured.get("tags")
    if not isinstance(tags, dict):
        return fields

    alias_to_field = {
        "prov": "C",
        "city": "C",
        "district": "D",
        "town": "D",
        "community": "D",
        "village_group": "D",
        "devzone": "AP",
        "road": "AP",
        "roadno": "AP",
        "intersection": "AP",
        "poi": "AP",
        "subpoi": "AP",
        "houseno": "AP",
        "cellno": "U",
        "floorno": "U",
        "roomno": "U",
        "detail": "U",
        "assist": "I",
        "distance": "I",
        "direction": "I",
    }

    collected: Dict[str, List[str]] = {"C": [], "D": [], "AP": [], "U": [], "I": [], "T": []}

    for key, value in tags.items():
        if not isinstance(key, str):
            continue
        key_stripped = key.strip()
        key_lower = key_stripped.lower()
        target = alias_to_field.get(key_lower)
        if not target and key_stripped in fields:
            target = key_stripped
        if not target:
            continue
        values = value if isinstance(value, list) else [value]
        for item in values:
            if item is None:
                continue
            text = str(item).strip()
            if not text:
                continue
            if text not in collected[target]:
                collected[target].append(text)

    for field in collected:
        if collected[field]:
            if field == "C":
                fields[field] = collected[field][0]
            else:
                fields[field] = "".join(collected[field])

    return fields

def resolve_address(raw_address: str) -> Dict:
    """
    åœ°å€æ™ºèƒ½è§£æä¸»æµç¨‹ï¼šç»“æ„åŒ–ã€æœç´¢ã€åŒ¹é…
    :param raw_address: åŸå§‹åœ°å€å­—ç¬¦ä¸²
    :return: åŒ¹é…åˆ°çš„æœ€ä½³ POI ä¿¡æ¯ï¼ˆå­—å…¸ï¼‰
    """
    start_time = time.time()  # âœ… å¯åŠ¨è®¡æ—¶
    logger.info(f"0. è¾“å…¥åœ°å€ï¼š{raw_address}")

    '''1. å…ˆæŸ¥ç§æœ‰åœ°å€åº“'''
    logger.info("1. ç§æœ‰åœ°å€åº“åŒ¹é…")
    private_matches = search_address(query=raw_address, page=1, page_size=3)
    if private_matches:
        best = private_matches[0]
        best["location"] = f"{best['lng']},{best['lat']}"  # è¡¥å…… location å­—æ®µ
        best["source"] = "custom"
        best["score"] = 100.0
        best["similarity"] = 100.0
        best["auxiliary"] = 0.0
        best["duration"] = round(time.time() - start_time, 2)
        logger.info(f"âœ… å‘½ä¸­ç§æœ‰åœ°å€åº“ï¼š{best['name']} | {best['address']}")
        return best

    '''2. å¿«é€Ÿ POI æœç´¢åŒ¹é…ï¼ˆä½¿ç”¨é«˜å¾· POI æœç´¢ + ç›¸ä¼¼åº¦ï¼‰'''
    logger.info("2. å¿«é€Ÿæœç´¢åŒ¹é…ï¼ˆamap_poi_searchï¼‰")
    pois = amap_poi_search("", raw_address)
    best_fast = get_best_poi(pois, raw_address) # type: ignore 

    # å­˜åœ¨åˆ†æ•°è¶…è¿‡70çš„ç»“æœ
    if best_fast:
        best_fast["regeo"] = regeo(best_fast["location"]) # ä¹¡é•‡ä¸€çº§ä¿¡æ¯åŒ¹é…
        best_fast["duration"] = round(time.time() - start_time, 2)
        return best_fast

    '''3. åœ°å€ç»“æ„åŒ–'''
    logger.info("3. åœ°å€ç»“æ„åŒ–")
    structured = infer(raw_address)

    logger.info(f"å¤§æ¨¡å‹è¿”å›ç»“æ„åŒ–ç»“æœï¼š{structured}")
    fields = build_structured_fields(raw_address, structured)
    city = fields.get("C", "")
    d = fields.get("D", "")
    ap = fields.get("AP", "")
    t = fields.get("T", "")
    i = fields.get("I", "")
    normalize_address = "".join(part for part in [d, ap, i] if part) or raw_address
    logger.info(
        f"ç»“æ„åŒ–å­—æ®µï¼šC={city} | D={d} | AP={ap} | U={fields.get('U', '')} | I={i} | T={t}"
    )

    '''4. POIæ¨è'''
    logger.info("4. POIæ¨è")
    search_keyword = f"{d}{ap}"
    logger.info(f"æœç´¢å…³é”®è¯ï¼š{city} {search_keyword} {t}")

    # ç¬¬ä¸€æ¬¡æœç´¢ï¼šä½¿ç”¨ D + AP
    pois = amap_inputtips(city, search_keyword, t)

    # å¦‚æœç»“æœå°‘äº 3 ä¸ªï¼Œå»æ‰åŸå¸‚æœ
    if len(pois) < 3:
        logger.info(f"ç»“æœè¾ƒå°‘ï¼Œå»æ‰åŸå¸‚æœç´¢ï¼š{search_keyword}")
        extra_pois = amap_inputtips('', search_keyword, '')
        pois = merge_pois(pois, extra_pois)
    
    
    city_1 = extract_first_region(d)
    if len(city_1) == 0:
        city_1 = city


    # å¦‚æœç»“æœå°‘äº 3 ä¸ª
    if len(pois) < 3:

        # å»æ‰ä¿®é¥°è¯
        search_keyword = re.sub(r'å®¿èˆ|\d+å·?(æ¥¼|æ ‹|åº§)|(ä¸œ|è¥¿)åŸ', '', search_keyword)
        search_keyword = re.sub(r'(?<=åŒº).+?é•‡', '', search_keyword)
        search_keyword = re.sub(r'å…¬ç§Ÿæˆ¿', '', search_keyword)
        logger.info(f"å»æ‰ä¿®é¥°è¯ï¼š{search_keyword}")
        extra_pois_1 = amap_inputtips('', search_keyword, '')

        # å¯èƒ½æ˜¯åœ°çº§å¸‚ç›´ç®¡å¿ï¼Œå°è¯•ç”¨ä¿®æ”¹åŸå¸‚åæœç´¢
        extra_pois_2 = []
        if len(city_1) > 0 and city_1 != city:
            logger.info(f"å¯èƒ½æ˜¯åœ°çº§å¸‚ç›´ç®¡å¿ï¼ˆ{city_1}ï¼‰ï¼š{ap}")
            extra_pois_2 = amap_inputtips(city_1, ap, '')

        extra_pois_3 = []
        search_keyword = re.sub(r'å®¿èˆ|\d+å·?(æ¥¼|æ ‹|åº§)', '', ap, count=0, flags=0)
        logger.info(f"ç–‘ä¼¼è¿‘éŸ³å­—è¯¯ç”¨ï¼Œåªæœæœç´¢APï¼š{search_keyword}")
        extra_pois_3 = amap_inputtips(city, search_keyword, '')

        pois = merge_pois(pois, extra_pois_1, extra_pois_2, extra_pois_3)

    # å¦‚æœç»“æœå°‘äº 3 ä¸ªï¼Œå†ç”¨ AP å•ç‹¬æœç´¢ä¸€æ¬¡
    # if len(pois) < 4:
    #     logger.info(f"ç»“æœè¾ƒå°‘ï¼Œå»æ‰åŸå¸‚åªæœåŸå§‹APï¼š{ap}")
    #     extra_pois = amap_inputtips('', ap, '')
    #     pois = merge_pois(pois, extra_pois)

    logger.info(f"å…œåº•è¡Œæ”¿åŒºæœç´¢ï¼š{city_1}")
    extra_pois = amap_inputtips('', city_1, '')
    extra_pois = extra_pois[:1] if extra_pois else []
    pois = merge_pois(pois, extra_pois)

    # æ— åŒ¹é… å…œåº•ç­–ç•¥ + æ¿€è¿›ç­–ç•¥
    if not pois:
        logger.info("5. POIæœªå‘½ä¸­ï¼Œå°è¯•å‘¨è¾¹æœç´¢")
        pois = search_nearby_by_fields(city, fields)

    if not pois:
        logger.error("âŒ POI æœç´¢æ— ç»“æœï¼Œè¿”å›ç©º")
        return {}

    def best_score(p: Dict, target: str, fields: Dict) -> float:
        """
        è®¡ç®—æœ€ç»ˆåŒ¹é…åˆ†æ•°ï¼šèåˆæ–‡æœ¬ç›¸ä¼¼åº¦å’Œè¾…åŠ©ç©ºé—´åˆ†æ•°
        :param p: POI å­—å…¸
        :param target: æ ‡å‡†åŒ–åœ°å€å­—ç¬¦ä¸²
        :return: èåˆåçš„åŒ¹é…å¾—åˆ†ï¼ˆ0~100ï¼‰
        """

        name_score = similarity_score(target, p['name'])
        address_score = similarity_score(target, p['address'])
        text_score = max(name_score, address_score)

        print(f"åˆå§‹æ–‡æœ¬ç›¸ä¼¼åº¦å¾—åˆ†: {text_score}")

        c = fields.get('C', '')

        if len(c) > 0 and c not in p["address"]:
            text_score = text_score * 0.8
        if len(city_1) > 0 and city_1 not in p["address"]:
            text_score = text_score * 0.8
        if len(c) > 0 and c not in p["address"] and len(city_1) > 0 and city_1 not in p["address"]:
            text_score = 0.0

        print(f"è°ƒæ•´åæ–‡æœ¬ç›¸ä¼¼åº¦å¾—åˆ†: {text_score}")

        # è¾…åŠ©è¯„åˆ†ï¼ˆç©ºé—´åˆ¤æ–­å¾—åˆ†ï¼‰
        aux_score = p.get("auxiliary_score", 0)

        # èåˆæ‰“åˆ†ï¼š70% æ–‡æœ¬ç›¸ä¼¼åº¦ + 30% ç©ºé—´å¾—åˆ†ï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´æƒé‡ï¼‰
        final_score = 0.7 * text_score + 0.3 * aux_score

        #print(f"èåˆåæœ€ç»ˆå¾—åˆ†: {final_score}")

        # ä¿å­˜åˆ° poi ä¸­ä¾¿äºæ‰“å°
        p['similarity'] = round(text_score, 2)
        p['auxiliary'] = round(aux_score, 2)
        p['score'] = round(final_score, 2)

        # logger.info(f"åç§°: {p.get('name', '')} | åœ°å€: {p.get('address', '')} --> text: {text_score:.2f} | aux: {aux_score:.2f} | final: {final_score:.2f}")

        return final_score

    best = max(pois, key=lambda p: best_score(p, normalize_address, fields))

    if len(best["location"].split(",")) != 2:
        logger.error(f"âŒ POI ä½ç½®ä¿¡æ¯å¼‚å¸¸ï¼š{best['location']}")
        return {}
    
    if best["score"] == 0:
        logger.error(f"âŒ POI ä¸åŒ¹é…ï¼š{best['score']}")
        return {}

    # è¡¥å…… ç»çº¬åº¦å­—æ®µ
    best["lat"] = float(best["location"].split(",")[1])
    best["lng"] = float(best["location"].split(",")[0])

    # è¡¥å……é€†åœ°ç†ç¼–ç ä¹¡é•‡è¡—é“ä¿¡æ¯
    best["regeo"] = regeo(best["location"])
    best["ap"] = ap
    best["structured"] = structured.get("tags", {})

    duration = round(time.time() - start_time, 2)  # âœ… è®¡ç®—è€—æ—¶
    logger.info(f"âœ… åŒ¹é…ç»“æœï¼š{best['name']} | {best['address']} | æœ€ç»ˆå¾—åˆ†: {best['score']} | æ–‡æœ¬: {best['similarity']} | ç©ºé—´: {best['auxiliary']}")
    best["duration"] = duration

    return best

# ç¤ºä¾‹è°ƒç”¨
if __name__ == "__main__":
    resolve_address("åŒ—äº¬å¸‚æµ·æ·€åŒºå…­é“å£è¥¿åŒ—è§’çš„ç¾Šè‚‰æ±¤é¦†")
